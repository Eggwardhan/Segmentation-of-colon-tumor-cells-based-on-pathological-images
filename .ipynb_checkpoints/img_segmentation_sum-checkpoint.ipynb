{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps\n",
    "import random\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import glob\n",
    "import multiprocessing\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import keras.callbacks as callbacks\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet with ResNet34 encoder (Pytorch)\n",
    "<code>https://www.kaggle.com/rishabhiitbhu/unet-with-resnet34-encoder-pytorch/notebook\\<code/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps\n",
    "import random\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import glob\n",
    "import multiprocessing\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import keras.callbacks as callbacks\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "Image.MAX_IMAGE_PIXELS=None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "train_mask_dir = \"../DigestPath2019/train_mask\" #create  train mask\n",
    "train_dir = \"../DigestPath2019/train\"\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        #nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        #nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Basic Block for resnet 18 and resnet 34\n",
    "    \"\"\"\n",
    "\n",
    "    # BasicBlock and BottleNeck block\n",
    "    # have different output size\n",
    "    # we use class attribute expansion\n",
    "    # to distinct\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # residual function\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "        )\n",
    "\n",
    "        # shortcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        # the shortcut output dimension is not the same with residual function\n",
    "        # use 1*1 convolution to match the dimension\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    \"\"\"Residual block for resnet over 50 layers\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channel,out_channel, block, num_block):\n",
    "        super().__init__()\n",
    "        #self.in_channels = in_channel\n",
    "        self.outc = out_channel #不能加self.out_channel  不是很懂为啥 估计是变量优先级问题\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, 64, kernel_size = 7, stride = 2, padding = 3,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # we use a different inputsize than the original paper\n",
    "        # so conv2_x's stride is 1\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "        # self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.dconv_last=nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(64,out_channel,1)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\"make resnet layers(by layer i didnt mean this 'layer' was the\n",
    "        same as a neuron netowork layer, ex. conv layer), one layer may\n",
    "        contain more than one residual block\n",
    "        Args:\n",
    "            block: block type, basic block or bottle neck block\n",
    "            out_channels: output depth channel number of this layer\n",
    "            num_blocks: how many blocks per layer\n",
    "            stride: the stride of the first block of this layer\n",
    "\n",
    "        Return:\n",
    "            return a resnet layer\n",
    "        \"\"\"\n",
    "\n",
    "        # we have num_block blocks per layer, the first block\n",
    "        # could be 1 or 2, other blocks would always be 1\n",
    "        strides = [stride] + [1] * (num_blocks - 1)# [stride, 1,1,1...]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        conv1 = self.conv1(x)\n",
    "        temp=self.maxpool(conv1)\n",
    "        print(temp.shape)\n",
    "        print(self.conv2_x)\n",
    "        conv2 = self.conv2_x(temp)\n",
    "        conv3 = self.conv3_x(conv2)\n",
    "        conv4 = self.conv4_x(conv3)\n",
    "        bottle = self.conv5_x(conv4)\n",
    "        # output = self.avg_pool(output)\n",
    "        # output = output.view(output.size(0), -1)\n",
    "        # output = self.fc(output)\n",
    "        x = self.upsample(bottle)\n",
    "        # print(x.shape)\n",
    "        # print(conv4.shape)\n",
    "        x = torch.cat([x, conv4], dim=1)\n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)\n",
    "        # print(x.shape)\n",
    "        # print(conv3.shape)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)\n",
    "        # print(x.shape)\n",
    "        # print(conv2.shape)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "        x=self.upsample(x)\n",
    "        # print(x.shape)\n",
    "        # print(conv1.shape)\n",
    "        x=torch.cat([x,conv1],dim=1)\n",
    "        out=self.dconv_last(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def load_pretrained_weights(self):\n",
    "         # 导入自己模型的参数\n",
    "        model_dict=self.state_dict()\n",
    "        \n",
    "        resnet34_weights = models.resnet34(True).state_dict()\n",
    "        count_res = 0\n",
    "        count_my = 0\n",
    "\n",
    "        reskeys = list(resnet34_weights.keys())\n",
    "        mykeys = list(model_dict.keys())\n",
    "        # print(self)  自己网络的结构\n",
    "        # print(models.resnet34())   resnet结构\n",
    "        # print(reskeys)\n",
    "        # print(mykeys)\n",
    "\n",
    "        corresp_map = []\n",
    "        while (True):              # 后缀相同的放入list\n",
    "            reskey = reskeys[count_res]\n",
    "            mykey = mykeys[count_my]\n",
    "\n",
    "            if \"fc\" in reskey:\n",
    "                break\n",
    "\n",
    "            while reskey.split(\".\")[-1] not in mykey:\n",
    "                count_my += 1\n",
    "                mykey = mykeys[count_my]\n",
    "\n",
    "            corresp_map.append([reskey, mykey])\n",
    "            count_res += 1\n",
    "            count_my += 1\n",
    "\n",
    "        for k_res, k_my in corresp_map:\n",
    "            model_dict[k_my]=resnet34_weights[k_res]\n",
    "\n",
    "        try:\n",
    "            self.load_state_dict(model_dict)\n",
    "            print(\"Loaded resnet34 weights in mynet !\")\n",
    "        except:\n",
    "            print(\"Error resnet34 weights in mynet !\")\n",
    "            raise\n",
    "\n",
    "\n",
    "def resnet18():\n",
    "    \"\"\" return a ResNet 18 object\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def resnet34(in_channel,out_channel,pretrain=True):\n",
    "    \"\"\" return a ResNet 34 object\n",
    "    \"\"\"\n",
    "    model=ResNet(in_channel,out_channel,BasicBlock, [3, 4, 6, 3])\n",
    "    if pretrain:\n",
    "        model.load_pretrained_weights()\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "    \"\"\" return a ResNet 50 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def resnet101():\n",
    "    \"\"\" return a ResNet 101 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def resnet152():\n",
    "    \"\"\" return a ResNet 152 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net = resnet34(3, 4, False) # out_channel = 4  4分类问题\n",
    "    #print(net)\n",
    "    x = torch.rand((1, 3, 512, 512)) #N，C, H, W\n",
    "    print(net.forward(x).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import model.model as model\n",
    "from eval import eval_net\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "Image.MAX_IMAGE_PIXELS=None\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "from eval import eval_net\n",
    "from unet import UNet\n",
    "from utils.dataset import BasicDataset\n",
    "'''\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_img(img):\n",
    "    plt.figure(figsize=(18,15))\n",
    "    # unnormalize\n",
    "    #npimg=Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "class BasicDataset(Dataset):\n",
    "    def __init__(self, imgs_dir, masks_dir, preprocess=None,scale=0.1, mask_suffix='_mask'):      \n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.preprocess= preprocess\n",
    "        #self.scale = scale\n",
    "        self.scale = 512\n",
    "        self.mask_suffix = mask_suffix\n",
    "\n",
    "        self.ids = [os.path.splitext(file)[0] for file in os.listdir(imgs_dir)\n",
    "                    if not file.startswith('.')]   # get prefix or so-called id\n",
    "        logging.info(f'Creating dataset with {len(self.ids)} examples')\n",
    "        #print(\"image_directory:{}  with {} files.\\nmask_dir:{}\".format(imgs_dir,len(self.ids),masks_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @classmethod\n",
    "    def process(cls, pil_img):\n",
    "        #w, h = pil_img.size\n",
    "        img = np.array(pil_img)\n",
    "        # unnormalize\n",
    "        opencvImage = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        #print(\"cv2 show by process\")\n",
    "        #cv2.imshow(\"sss\",opencvImage)\n",
    "        \n",
    "        return opencvImage\n",
    "        #newW, newH = int(scale * w), int(scale * h)\n",
    "        #assert w > 0 and h > 0, 'Scale is too small\n",
    "        #pil_img = pil_img.resize((size, size))\n",
    "\n",
    "        ''' img_nd = np.array(pil_img)\n",
    "\n",
    "        if len(img_nd.shape) == 2:\n",
    "            img_nd = np.expand_dims(img_nd, axis=2)\n",
    "\n",
    "        # HWC to CHW\n",
    "        img_trans = img_nd.transpose((2, 0, 1))\n",
    "        if img_trans.max() > 1:\n",
    "            img_trans = img_trans / 255\n",
    "\n",
    "        return img_trans'''\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.ids[i]\n",
    "        temp = os.path.join(self.masks_dir,idx+self.mask_suffix+'.*')\n",
    "        mask_file = glob.glob(temp)\n",
    "\n",
    "        img_file = glob.glob(os.path.join(self.imgs_dir , idx + '.*'))\n",
    "\n",
    "        assert len(mask_file) == 1, \\\n",
    "            f'Either no mask or multiple masks found for the ID {idx}: {mask_file}'\n",
    "        assert len(img_file) == 1, \\\n",
    "            f'Either no image or multiple images found for the ID {idx}: {img_file}'\n",
    "        mask = Image.open(mask_file[0])\n",
    "        #print(mask_file[0])\n",
    "        img = Image.open(img_file[0])\n",
    "        assert img.size == mask.size, \\\n",
    "            f'Image and mask {idx} should be the same size, but are {img.size} and {mask.size}'\n",
    "        img = self.process(img)\n",
    "        mask = self.process(mask)\n",
    "        if self.preprocess!= None:\n",
    "            transformed = self.preprocess(image=img,mask=mask)\n",
    "            img= transformed['image']\n",
    "            mask= transformed['mask']\n",
    "        img_trans = img.transpose((2, 0, 1))\n",
    "        if img_trans.max() > 1:\n",
    "            img_trans = img_trans / 255\n",
    "        #print(mask.shape)\n",
    "        Grayimg = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask_trans = cv2.threshold(Grayimg, 12, 255,cv2.THRESH_BINARY)\n",
    "\n",
    "        \n",
    "        _ = {\n",
    "            'image': torch.from_numpy(img_trans).type(torch.FloatTensor),\n",
    "            'mask': torch.from_numpy(mask_trans).type(torch.FloatTensor).unsqueeze(0)\n",
    "        }      \n",
    "        print(\"image final .shape\",_['image'].shape)\n",
    "\n",
    "        print(\"mask final .shape\",_['mask'].shape)\n",
    "        #show_img(img)\n",
    "        return _\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n",
    "    RandomBrightness, RandomContrast, RandomGamma,OneOf,\n",
    "    ToFloat, ShiftScaleRotate,GridDistortion, ElasticTransform, JpegCompression, HueSaturationValue,\n",
    "    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise,CenterCrop,\n",
    "    IAAAdditiveGaussianNoise,GaussNoise,OpticalDistortion,RandomSizedCrop\n",
    ")\n",
    "size = 512\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    OneOf([\n",
    "        RandomContrast(),\n",
    "        RandomGamma(),\n",
    "        RandomBrightness()\n",
    "    ], p=0.3),\n",
    "    OneOf([\n",
    "        ElasticTransform(alpha = 120, sigma=120*0.05,alpha_affine = 12*0.03),\n",
    "        GridDistortion(),\n",
    "        OpticalDistortion(distort_limit = 2, shift_limit = 0.5)\n",
    "    ], p=0.3),\n",
    "    RandomSizedCrop(min_max_height=(512,1024),height = size, width =size,p=1),\n",
    "    ToFloat(max_value=1)\n",
    "], p =1)\n",
    "\n",
    "AUGMENTATIONS_TEST = Compose([\n",
    "    ToFloat(max_value=1)\n",
    "],p=1)\n",
    "def show_img(img):\n",
    "    plt.figure(figsize=(18,15))\n",
    "    # unnormalize\n",
    "    #npimg=Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    plt.imshow(img.astype(int))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_url=\"../Colonoscopy_tissue_segment_dataset/train/1902160001_2019-06-11 12_36_32-lv1-39045-16016-3312-4096.jpg\"\n",
    "image = Image.open(img_url)\n",
    "img = np.array(image)\n",
    "\n",
    "print(img.size)\n",
    "\n",
    "print(image.size)\n",
    "\n",
    "opencvImage = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# unnormalize\n",
    "print(\"cv2 show by process\")\n",
    "#cv2.imshow(\"sss\",opencvImage)\n",
    "opencvImage=AUGMENTATIONS_TRAIN(image=opencvImage)['image']\n",
    "print(opencvImage.shape)\n",
    "img = opencvImage.transpose((2, 0, 1))\n",
    "if img.max() > 1:\n",
    "    img = img / 255 \n",
    "print(img.shape)\n",
    "\n",
    "tmp = torch.from_numpy(img).type(torch.FloatTensor)\n",
    "\n",
    "print(\"tmp\",tmp.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/eggwardhan/Documents/cv/Segmentation-of-colon-tumor-cells-based-on-pathological-images/check_point/nest_unet.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-06bcdf06bc29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m net.load_state_dict(\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/eggwardhan/Documents/cv/Segmentation-of-colon-tumor-cells-based-on-pathological-images/check_point/nest_unet.pth'"
     ]
    }
   ],
   "source": [
    "import predict \n",
    "from train import BasicDataset\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import model.model as model\n",
    "from eval import eval_net\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "from augment import AUGMENTATIONS_TEST2 as AUGMENTATIONS_TEST\n",
    "Image.MAX_IMAGE_PIXELS=None\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "from eval import eval_net\n",
    "from unet import UNet\n",
    "from utils.dataset import BasicDataset\n",
    "'''\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "import cv2\n",
    "device = \"cpu\"\n",
    "img_url = \"../Colonoscopy_tissue_segment_dataset/val/18_00991B_2019-05-07 21_27_54-lv1-16174-30030-3538-5736.jpg\"\n",
    "\n",
    "load=\"/Users/eggwardhan/Documents/cv/Segmentation-of-colon-tumor-cells-based-on-pathological-images/check_point/nest_unet.pth\"\n",
    "net = model.choose_net(\"nested_unet\")\n",
    "\n",
    "net = net(in_channel=3,out_channel=1)\n",
    "net.load_state_dict(\n",
    "            torch.load(load, map_location=device)\n",
    "            )\n",
    "\n",
    "def total_predict(ori_image):\n",
    "    # PIL Get image size (width, height) \n",
    "    # nparray get image size (row (height), column (width), color (3))\n",
    "    img =Image.open(img_url)\n",
    "    #print(img.size)\n",
    "    ori_image=np.array(img)\n",
    "    #ori_image = process(ori_image)\n",
    "    #print(\"ori_image:\",ori_image.shape)\n",
    "    h_step = ori_image.shape[0]//256\n",
    "    w_step = ori_image.shape[1]//256\n",
    "\n",
    "    h_rest = -(ori_image.shape[0] - 256 * h_step)\n",
    "    w_rest = -(ori_image.shape[1] - 256 * w_step)\n",
    "    image_list = []\n",
    "    predict_list = []\n",
    "    for h in range(h_step):      # 截取片段\n",
    "        for w in range(w_step):\n",
    "            image_sample = ori_image[ (h*256):(h*256+256),\n",
    "            (w*256 ) : (w*256 + 256), : ]/255\n",
    "            image_list.append(image_sample)  \n",
    "        image_list.append(ori_image[( h* 256) : (h*256 +256), -256:, :]/255)\n",
    "    for w in range(w_step-1):   \n",
    "        image_list.append(ori_image[-256:, (w*256):(w*256 +256), :]/255)\n",
    "    image_list.append(ori_image[-256:, -256:, :]/255)\n",
    "\n",
    "    for image in image_list:       \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = torch.from_numpy(image).type(torch.FloatTensor)\n",
    "        image = image.unsqueeze(0)\n",
    "        #print(image.shape)\n",
    "        image.to(device=\"cuda\", dtype=torch.float32)\n",
    "        pred1 = net(image)\n",
    "        pred1 = pred1.squeeze(0).squeeze(0)  # 2 dimension\n",
    "        pred = pred1>threshold\n",
    "        predict_list.append(pred)\n",
    "    count_temp = 0\n",
    "    tmp = np.ones([ori_image.shape[0],ori_image.shape[1]])\n",
    "    for h in range(h_step):\n",
    "        for w in range(w_step):\n",
    "            tmp[\n",
    "                h*256:(h+1)*256,\n",
    "                w*256:(w+1)*256\n",
    "            ] = predict_list[count_temp]\n",
    "            count_temp += 1\n",
    "        tmp[h *256 :(h+1) *256, w_rest:] = predict_list[count_temp][:, w_rest:]\n",
    "        count_temp+=1\n",
    "    for w in range(w_step -1):\n",
    "        tmp[h_rest:, (w *256):(w*256+256)] = predict_list[count_temp][h_rest:,:]\n",
    "        count_temp+=1\n",
    "    tmp[-257:-1,-257:-1] = predict_list[count_temp][:, :]\n",
    "\n",
    "pred= total_predict(Image.open(img_url))\n",
    "#print(type(pred))\n",
    "#print(pred)\n",
    "show_img(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cuda:1\n",
      "INFO: Network:\n",
      "\t3 input channels\n",
      "\t1 output channels (classes)\n",
      "\tBilinear upscaling\n",
      "INFO: Creating dataset with 297 examples\n",
      "INFO: Creating dataset with 33 examples\n",
      "INFO: Starting training:\n",
      "        Epochs:          20\n",
      "        Batch size:      4\n",
      "        Criterion:       dice\n",
      "        Learning rate:   0.0001\n",
      "        Training size:   297\n",
      "        Validation size: 33\n",
      "        Checkpoints:     True\n",
      "        Device:          cuda\n",
      "        Images scaling:  256\n",
      "    \n",
      "Epoch 1/20:   0%|          | 0/297 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 3.4491e-01,  2.7595e-03, -7.6834e-04,  ..., -8.2068e-02,\n",
      "            9.7114e-02,  2.2718e-01],\n",
      "          [ 1.7346e-01,  2.4779e-01,  1.1798e+00,  ..., -1.8891e-01,\n",
      "           -2.4642e-01, -5.6187e-03],\n",
      "          [ 1.6272e-02, -3.5216e-01,  1.0862e+00,  ..., -3.0392e-01,\n",
      "            2.0165e-01, -3.6207e-02],\n",
      "          ...,\n",
      "          [-4.4188e-01,  8.8159e-01,  3.0309e-01,  ...,  4.8164e-01,\n",
      "            6.3378e-01,  6.2472e-01],\n",
      "          [-3.0909e-01,  3.9137e-01,  5.7200e-01,  ...,  5.2919e-01,\n",
      "            8.2470e-01,  5.0888e-01],\n",
      "          [-9.4287e-02,  2.9137e-01, -4.5511e-02,  ...,  3.8781e-01,\n",
      "           -6.4093e-02,  2.1319e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2156e-01,  2.0056e-01,  1.6058e-01,  ...,  1.9715e-01,\n",
      "            1.3693e-01,  2.4335e-01],\n",
      "          [ 2.8632e-01,  2.2715e-01,  2.6833e-01,  ..., -1.9090e-01,\n",
      "           -2.7905e-01,  7.9542e-02],\n",
      "          [ 2.1461e-01, -2.7780e-01, -1.9372e-01,  ..., -2.2809e-01,\n",
      "            5.0619e-01,  2.4057e-01],\n",
      "          ...,\n",
      "          [ 4.5227e-02,  1.0607e-01, -7.0911e-02,  ...,  4.6373e-01,\n",
      "            5.5793e-01,  5.8030e-01],\n",
      "          [-1.6548e-01,  2.8307e-01,  3.7403e-01,  ...,  5.1787e-01,\n",
      "            8.0083e-01,  4.6965e-01],\n",
      "          [-9.2204e-02,  1.9740e-01,  2.3616e-01,  ...,  3.5030e-01,\n",
      "           -9.4857e-02,  2.1115e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4845e-01,  1.0570e-01, -2.1854e-01,  ...,  4.4520e-02,\n",
      "            4.7715e-01,  3.7001e-01],\n",
      "          [ 4.3066e-01, -8.0392e-02,  1.5178e+00,  ...,  2.0893e-01,\n",
      "           -1.1777e-01,  3.9879e-03],\n",
      "          [-2.4262e-03, -3.6222e-01,  8.6399e-01,  ...,  4.0824e-01,\n",
      "            1.7239e-01,  1.6518e-01],\n",
      "          ...,\n",
      "          [-5.4789e-01,  9.7317e-01,  9.5524e-01,  ..., -8.7292e-02,\n",
      "            2.1262e-01,  1.2363e-01],\n",
      "          [-5.3719e-01,  7.3490e-01,  9.5631e-01,  ...,  1.1656e-01,\n",
      "           -6.6275e-03,  3.6289e-01],\n",
      "          [-1.4977e-01,  4.6662e-01,  1.9284e-01,  ..., -6.6405e-02,\n",
      "           -4.4019e-02,  5.4846e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0398e-01,  5.5924e-02, -1.5994e-01,  ...,  7.2049e-01,\n",
      "            6.8658e-01,  3.0245e-01],\n",
      "          [ 3.7360e-01, -9.2896e-03,  1.4244e+00,  ..., -5.8251e-01,\n",
      "            2.4678e-01, -2.1171e-01],\n",
      "          [-2.7669e-02, -2.6795e-01,  8.5824e-01,  ..., -1.4819e-01,\n",
      "            1.4275e-01,  2.8343e-02],\n",
      "          ...,\n",
      "          [-5.6566e-01,  9.6530e-01,  9.6001e-01,  ...,  4.5887e-01,\n",
      "            6.5447e-01,  5.9840e-01],\n",
      "          [-5.5387e-01,  7.5565e-01,  9.7975e-01,  ...,  5.4296e-01,\n",
      "            8.0719e-01,  4.9814e-01],\n",
      "          [-1.5719e-01,  4.7261e-01,  2.1166e-01,  ...,  3.9652e-01,\n",
      "           -6.4409e-02,  1.8953e-01]]]], device='cuda:1',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   1%|▏         | 4/297 [01:02<1:15:21, 15.43s/img, loss (batch)=0.746]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2774, -0.0647, -0.2483,  ...,  0.2307,  0.5539,  0.1920],\n",
      "          [ 0.4795,  0.1291,  1.4750,  ..., -0.0178,  0.1042,  0.2315],\n",
      "          [ 0.1540, -0.2033,  1.2270,  ...,  0.5046,  0.0050,  0.5196],\n",
      "          ...,\n",
      "          [-0.4275,  0.9786,  1.4404,  ...,  0.1442,  0.5067,  0.6818],\n",
      "          [-0.5848,  0.4987,  0.9757,  ...,  0.7160,  0.9056,  0.8321],\n",
      "          [-0.1183,  0.3183,  0.3042,  ...,  0.3164, -0.1011,  0.2457]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2408, -0.0675, -0.1054,  ...,  0.2783,  0.2037,  0.2909],\n",
      "          [ 0.6060,  0.4699,  0.5845,  ..., -0.4599, -0.2974, -0.1158],\n",
      "          [ 0.1349, -0.0443,  0.7231,  ...,  0.3006, -0.0434,  0.1315],\n",
      "          ...,\n",
      "          [-0.3603,  1.0487,  0.8110,  ...,  0.0134,  0.3507,  0.1801],\n",
      "          [-0.0284,  0.6914,  0.6858,  ...,  0.1019, -0.0040,  0.4299],\n",
      "          [-0.2156,  0.2781, -0.1025,  ...,  0.4009, -0.2499,  0.0052]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2846, -0.0223, -0.2354,  ...,  0.4054,  0.8782,  0.5915],\n",
      "          [ 0.0134,  0.2492,  1.2381,  ...,  0.0591,  0.0674, -0.0518],\n",
      "          [ 0.0058, -0.1577,  0.9795,  ...,  0.1776,  0.3874,  0.1630],\n",
      "          ...,\n",
      "          [-0.1138,  0.6212,  1.1750,  ..., -0.2287,  0.0691,  0.4997],\n",
      "          [-0.0231,  0.1603,  0.6060,  ...,  0.4734,  0.3776,  0.5936],\n",
      "          [ 0.0398, -0.2092,  0.4046,  ..., -0.0684,  0.1461,  0.1125]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2696, -0.0844, -0.2466,  ...,  0.1951,  0.5491,  0.2565],\n",
      "          [ 0.4955,  0.1308,  1.4841,  ...,  0.0949,  0.0913,  0.3123],\n",
      "          [ 0.1546, -0.2087,  1.2316,  ...,  0.5070, -0.1158,  0.5276],\n",
      "          ...,\n",
      "          [-0.4553,  0.8963,  1.1236,  ...,  0.1080,  1.0054,  0.4611],\n",
      "          [-0.4550,  0.5431,  0.7904,  ...,  0.1284,  0.3167,  0.2901],\n",
      "          [-0.0856,  0.2396,  0.0758,  ...,  0.1067,  0.4054,  0.1578]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   3%|▎         | 8/297 [01:03<31:29,  6.54s/img, loss (batch)=0.922]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2795,  0.2279, -0.0495,  ...,  0.5737,  0.6217,  0.2685],\n",
      "          [ 0.0897,  0.3667,  0.5120,  ...,  0.2259,  0.5533,  0.3655],\n",
      "          [ 0.0281, -0.0715,  0.8339,  ...,  0.4827,  0.2779,  0.6835],\n",
      "          ...,\n",
      "          [-0.7014,  1.3937,  1.0184,  ...,  0.5547,  0.7410,  0.9337],\n",
      "          [-0.6331,  0.8603,  0.9877,  ...,  0.6391,  1.3253,  0.9885],\n",
      "          [ 0.0267,  0.7067,  0.6808,  ...,  0.3338,  0.2165,  0.4316]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1963,  0.0632, -0.1856,  ...,  0.3953,  0.5250,  0.3024],\n",
      "          [ 0.4790,  0.4055,  0.3445,  ...,  0.3256,  0.4193,  0.1965],\n",
      "          [ 0.1010, -0.0634,  0.3548,  ...,  0.5238,  0.1119,  0.5718],\n",
      "          ...,\n",
      "          [-0.1143,  0.4072,  0.8108,  ...,  0.4014,  0.6965,  0.7574],\n",
      "          [ 0.0131,  0.3757,  1.0695,  ...,  0.4417,  1.1091,  0.7936],\n",
      "          [ 0.0117,  0.3449,  0.7838,  ...,  0.3731,  0.1027,  0.2474]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1346, -0.0627, -0.0493,  ...,  0.4293,  0.5851,  0.3272],\n",
      "          [ 0.4137,  1.0905,  1.0340,  ...,  0.4326,  0.4417,  0.2454],\n",
      "          [-0.0941,  0.1148,  1.0463,  ...,  0.6009,  0.0974,  0.5215],\n",
      "          ...,\n",
      "          [-0.3404,  0.7313,  0.3492,  ...,  0.1864,  0.4053,  0.0748],\n",
      "          [-0.1573,  0.5538,  0.4473,  ..., -0.0773,  0.2578,  0.3639],\n",
      "          [-0.0523,  0.3466,  0.1545,  ...,  0.1187,  0.1081,  0.0385]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2357,  0.6650,  0.7185,  ...,  0.8846,  0.6327,  0.4258],\n",
      "          [ 0.3783,  0.5477,  0.5152,  ..., -0.0106,  0.9853,  0.1937],\n",
      "          [ 0.1795,  0.1508,  0.1053,  ...,  0.7604,  0.6177,  0.2489],\n",
      "          ...,\n",
      "          [-0.3979,  0.6269,  0.6573,  ...,  0.1194,  0.3000,  0.1510],\n",
      "          [-0.1664,  0.7141,  0.8737,  ..., -0.0584,  0.2173,  0.3935],\n",
      "          [ 0.0172,  0.3900,  0.6248,  ...,  0.3807,  0.1166,  0.0501]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   4%|▍         | 12/297 [01:04<17:39,  3.72s/img, loss (batch)=1]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2878, -0.0173, -0.1841,  ...,  0.2716,  0.4932,  0.3791],\n",
      "          [ 0.4085,  0.4994,  1.0706,  ...,  0.1934,  0.3699,  0.4111],\n",
      "          [ 0.0472,  0.0459,  0.9508,  ...,  0.6322, -0.0181,  0.2039],\n",
      "          ...,\n",
      "          [-0.6534,  1.0515,  1.0688,  ...,  0.3324,  0.4796,  0.5954],\n",
      "          [-0.6570,  0.4429,  0.9825,  ...,  0.5587,  0.8859,  0.6201],\n",
      "          [ 0.0125,  0.3891,  0.3597,  ...,  0.4051,  0.0566,  0.2190]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3761,  0.0101, -0.2197,  ...,  0.3068,  0.5392,  0.4038],\n",
      "          [ 0.3049, -0.0014,  0.9400,  ...,  0.1903,  0.4072,  0.3812],\n",
      "          [ 0.1106,  0.0888,  0.7709,  ...,  0.6436,  0.0086,  0.2063],\n",
      "          ...,\n",
      "          [-0.3026,  0.3311,  0.2674,  ...,  0.2653,  0.3630,  0.0931],\n",
      "          [-0.1107,  0.0117,  0.5673,  ...,  0.0224,  0.1558,  0.3175],\n",
      "          [ 0.0824,  0.3028,  0.4136,  ...,  0.4520,  0.0590,  0.0973]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3063,  0.4771,  0.3165,  ...,  0.9725,  0.6350,  0.6831],\n",
      "          [ 0.0256,  0.1912,  0.6413,  ...,  0.5342,  0.0532,  0.2401],\n",
      "          [ 0.1252, -0.1914,  0.3749,  ...,  0.2145,  0.3376,  0.3601],\n",
      "          ...,\n",
      "          [-0.1319,  0.3727,  0.2821,  ...,  0.6523,  0.8605,  0.6911],\n",
      "          [-0.0819,  0.0376,  0.3262,  ...,  0.5399,  0.9098,  0.6957],\n",
      "          [ 0.1434,  0.2243,  0.4991,  ...,  0.0749, -0.0546,  0.1894]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3669,  0.2840,  0.0851,  ...,  0.2137,  0.4776,  0.3691],\n",
      "          [ 0.2430,  0.4206,  0.5674,  ...,  0.1556,  0.4253,  0.4415],\n",
      "          [-0.0642,  0.1866,  0.4238,  ...,  0.5948,  0.0635,  0.2240],\n",
      "          ...,\n",
      "          [-0.3986,  1.1469,  1.2038,  ...,  0.3236,  0.4363,  0.5896],\n",
      "          [-0.5079,  0.5373,  1.0813,  ...,  0.5751,  0.8957,  0.6544],\n",
      "          [ 0.0588,  0.3625,  0.5442,  ...,  0.3792,  0.0774,  0.2645]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   5%|▌         | 16/297 [01:06<11:06,  2.37s/img, loss (batch)=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0931, -0.0734, -0.3256,  ...,  0.3743,  0.5235,  0.2794],\n",
      "          [ 0.3335,  0.6525,  0.6699,  ...,  0.4118,  0.3546,  0.3219],\n",
      "          [ 0.2035,  0.1305,  0.5725,  ...,  0.4116,  0.0027,  0.3278],\n",
      "          ...,\n",
      "          [-0.2053,  0.4491,  0.7534,  ...,  0.5178,  0.3892,  0.5253],\n",
      "          [-0.1833,  0.1138,  0.8790,  ...,  0.5854,  0.8345,  0.7285],\n",
      "          [ 0.1615,  0.1411,  0.4276,  ...,  0.4680, -0.0909,  0.2199]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2497,  0.3545,  0.3036,  ...,  0.6001,  0.6161,  0.2665],\n",
      "          [ 0.3590,  0.7285,  0.7076,  ...,  0.2314,  0.0623, -0.0232],\n",
      "          [ 0.1496,  0.0399, -0.0366,  ...,  0.7200, -0.0520, -0.0351],\n",
      "          ...,\n",
      "          [-0.2236,  0.4661,  0.2988,  ...,  0.2947,  0.1485,  0.1897],\n",
      "          [ 0.2027,  0.3307,  0.4764,  ...,  0.1700,  0.0796,  0.1977],\n",
      "          [ 0.1371,  0.2902,  0.2168,  ...,  0.3207, -0.0308,  0.0897]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2683,  0.0867, -0.2344,  ...,  0.5731,  0.6530,  0.3802],\n",
      "          [ 0.5677,  0.3244,  0.3252,  ...,  0.3403,  0.4936,  0.0587],\n",
      "          [-0.0392, -0.4897,  0.0237,  ...,  0.1508,  0.3295,  0.5627],\n",
      "          ...,\n",
      "          [-0.2239,  0.9457,  0.6346,  ...,  0.2061,  0.3162,  0.7584],\n",
      "          [-0.2941,  0.5213,  0.9557,  ...,  0.4185,  0.8136,  0.8703],\n",
      "          [-0.0431,  0.2032,  0.1914,  ...,  0.2762,  0.1176,  0.3849]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0293,  0.3836,  0.3259,  ...,  0.3680,  0.5216,  0.2838],\n",
      "          [ 0.2280,  0.5241,  0.6944,  ...,  0.4010,  0.3507,  0.3171],\n",
      "          [ 0.0981,  0.0360, -0.0385,  ...,  0.5188,  0.0270,  0.2701],\n",
      "          ...,\n",
      "          [-0.0165,  0.0788,  0.4292,  ...,  0.2010,  0.3277,  0.7507],\n",
      "          [ 0.0753, -0.0893,  0.6853,  ...,  0.3474,  0.8309,  0.7918],\n",
      "          [ 0.1269,  0.0596,  0.4001,  ...,  0.2748,  0.0688,  0.3559]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   7%|▋         | 20/297 [01:07<07:30,  1.63s/img, loss (batch)=0.965]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1314,  0.2093, -0.1211,  ...,  0.3386,  0.5181,  0.2367],\n",
      "          [ 0.2661,  0.4460,  0.4733,  ...,  0.0924,  0.1989,  0.1180],\n",
      "          [-0.0577, -0.0012,  0.7646,  ...,  0.0672, -0.0215,  0.4501],\n",
      "          ...,\n",
      "          [-0.2969,  0.1491,  0.1902,  ..., -0.2135,  0.0210,  0.5564],\n",
      "          [ 0.0033,  0.1666,  0.5458,  ...,  0.1599,  0.4905,  0.4436],\n",
      "          [ 0.1770,  0.4294,  0.4615,  ...,  0.0199,  0.0597,  0.2423]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1510,  0.2320,  0.1506,  ...,  0.3687,  0.5212,  0.2385],\n",
      "          [ 0.5891,  0.8127,  0.5057,  ...,  0.1111,  0.1921,  0.1284],\n",
      "          [ 0.2157,  0.0525,  0.5486,  ...,  0.0887,  0.0168,  0.4728],\n",
      "          ...,\n",
      "          [-0.1732, -0.2352, -0.0408,  ...,  0.0821,  0.2081,  0.8707],\n",
      "          [ 0.0139, -0.0626,  0.4631,  ...,  0.1228,  0.4476,  0.6691],\n",
      "          [ 0.0936,  0.0761,  0.5011,  ...,  0.2208, -0.0558,  0.3233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1570,  0.3894,  0.6486,  ...,  0.3057,  0.4664,  0.2447],\n",
      "          [ 0.1683,  0.5067,  0.7704,  ...,  0.2378,  0.0828,  0.1814],\n",
      "          [ 0.1311,  0.1004,  0.3931,  ...,  0.3980,  0.1021,  0.0485],\n",
      "          ...,\n",
      "          [-0.2637,  0.7769,  0.4865,  ...,  0.2717, -0.0183,  0.1859],\n",
      "          [-0.3596,  0.3188,  0.7675,  ...,  0.2215,  0.2058,  0.2127],\n",
      "          [-0.0606,  0.2301,  0.2180,  ...,  0.2864, -0.1674,  0.0473]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2010,  0.2611, -0.0612,  ...,  0.2383,  0.2716,  0.2453],\n",
      "          [-0.2040,  0.1968,  0.2328,  ...,  0.2551,  0.1983,  0.2503],\n",
      "          [-0.0985, -0.2243,  0.2833,  ...,  0.5232,  0.2166,  0.2360],\n",
      "          ...,\n",
      "          [-0.3419,  0.9304,  0.8414,  ...,  0.3158,  0.1666,  0.4908],\n",
      "          [-0.4093,  0.3597,  0.6930,  ..., -0.0328,  0.1155,  0.2557],\n",
      "          [ 0.1139,  0.6114,  0.5184,  ...,  0.4516,  0.1616,  0.2379]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   8%|▊         | 24/297 [01:08<05:25,  1.19s/img, loss (batch)=1]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.4692, -0.0380, -0.2510,  ...,  0.1314,  0.4705,  0.2306],\n",
      "          [ 0.3684, -0.0025,  0.8266,  ...,  0.2863,  0.1529,  0.1458],\n",
      "          [ 0.4355,  0.3323,  0.6661,  ...,  1.1724,  0.4979,  0.1441],\n",
      "          ...,\n",
      "          [-0.4313,  1.1834,  1.1668,  ...,  0.6705,  0.2724,  0.6617],\n",
      "          [-0.4469,  0.2631,  1.2892,  ...,  0.9189,  0.8277,  0.3182],\n",
      "          [ 0.1397,  0.2504,  0.4032,  ...,  0.2795,  0.0359,  0.3243]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4099, -0.0664, -0.2945,  ...,  0.0636,  0.2779,  0.2973],\n",
      "          [ 0.3035, -0.0820,  0.7472,  ...,  0.3480,  0.0488,  0.3387],\n",
      "          [ 0.4559,  0.3223,  0.5562,  ...,  1.4726,  0.5950,  0.3730],\n",
      "          ...,\n",
      "          [-0.0616,  0.1952,  0.6491,  ...,  0.6378,  0.3466,  0.6563],\n",
      "          [ 0.0766, -0.2140,  0.5377,  ...,  0.7256,  0.7921,  0.2061],\n",
      "          [ 0.2945,  0.4340,  0.5085,  ...,  0.3238,  0.0057,  0.2946]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1202,  0.8952,  0.9736,  ...,  0.3759,  0.7267,  0.6538],\n",
      "          [ 0.1339,  0.7083,  0.7134,  ...,  0.4073,  0.5810,  0.3090],\n",
      "          [ 0.1825,  0.0136, -0.4660,  ...,  0.2632,  0.3793,  0.3371],\n",
      "          ...,\n",
      "          [-0.4008,  0.5756,  0.8119,  ...,  0.7121,  0.2285,  0.5096],\n",
      "          [-0.1154,  0.1707,  1.0741,  ...,  0.9475,  0.7070,  0.1792],\n",
      "          [ 0.1673,  0.2005,  0.4645,  ...,  0.4097, -0.0306,  0.2181]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4884, -0.0199, -0.2516,  ...,  0.0699,  0.3107,  0.2963],\n",
      "          [ 0.3168, -0.0300,  0.7929,  ...,  0.3156,  0.0742,  0.3967],\n",
      "          [ 0.4398,  0.3159,  0.6135,  ...,  1.4165,  0.6107,  0.3525],\n",
      "          ...,\n",
      "          [-0.4677,  1.1399,  1.1561,  ...,  0.6317,  0.4390,  0.7083],\n",
      "          [-0.4400,  0.2854,  1.2914,  ...,  0.7664,  0.9090,  0.2760],\n",
      "          [ 0.1289,  0.2428,  0.3735,  ...,  0.3147,  0.0549,  0.3442]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   9%|▉         | 28/297 [01:09<04:05,  1.10img/s, loss (batch)=1]INFO: item_loss: 6.5433443784713745\n",
      "\n",
      "Validation round:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  12%|█▎        | 1/8 [01:53<13:15, 113.58s/batch]\u001b[A\n",
      "Validation round:  25%|██▌       | 2/8 [01:54<04:42, 47.15s/batch] \u001b[A\n",
      "Validation round:  38%|███▊      | 3/8 [01:54<02:08, 25.75s/batch]\u001b[A\n",
      "Validation round:  50%|█████     | 4/8 [02:05<01:19, 19.88s/batch]\u001b[A\n",
      "Validation round:  62%|██████▎   | 5/8 [02:06<00:38, 12.96s/batch]\u001b[A\n",
      "Validation round:  75%|███████▌  | 6/8 [02:06<00:17,  8.65s/batch]\u001b[A\n",
      "Validation round:  88%|████████▊ | 7/8 [02:11<00:07,  7.56s/batch]\u001b[A\n",
      "Validation round: 100%|██████████| 8/8 [02:11<00:00,  5.24s/batch]\u001b[A\n",
      "                                                                  \u001b[AINFO: lr: 0.0001\n",
      "INFO: Validation Dice Coeff: 0.13030407198350877\n",
      "Epoch 1/20:   9%|▉         | 28/297 [03:39<04:05,  1.10img/s, loss (batch)=0.658]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5887e-01,  2.2473e-01,  1.6922e-01,  ...,  5.3202e-01,\n",
      "            4.4238e-01,  2.7073e-01],\n",
      "          [ 3.6413e-01,  6.2261e-01,  5.8829e-01,  ...,  5.9298e-01,\n",
      "            1.3386e-01,  1.0279e-01],\n",
      "          [ 2.3234e-01,  4.4062e-01,  4.6830e-01,  ...,  8.1105e-01,\n",
      "            9.3242e-02,  4.8354e-02],\n",
      "          ...,\n",
      "          [ 2.4412e-02,  5.8335e-01,  8.6948e-01,  ...,  3.2369e-01,\n",
      "            6.4683e-01,  5.0534e-01],\n",
      "          [-1.1046e-01,  2.3211e-01,  9.4388e-01,  ...,  3.0374e-01,\n",
      "            3.8031e-01,  4.7829e-01],\n",
      "          [ 2.9645e-01,  3.0567e-01,  6.3421e-01,  ...,  4.9873e-01,\n",
      "            2.0205e-01,  3.0584e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9788e-01,  9.7132e-02, -8.1781e-04,  ...,  2.9115e-01,\n",
      "            4.3646e-01,  1.3874e-01],\n",
      "          [ 4.3033e-01,  2.9965e-01,  3.0516e-01,  ...,  7.8720e-02,\n",
      "            1.0054e-01, -1.4130e-01],\n",
      "          [ 2.2925e-01, -4.1329e-02,  2.9789e-01,  ...,  2.7352e-01,\n",
      "            7.9024e-02,  1.6290e-01],\n",
      "          ...,\n",
      "          [-2.0422e-01,  1.0418e+00,  1.1285e+00,  ...,  1.5376e-01,\n",
      "            3.0757e-01,  7.6533e-01],\n",
      "          [-5.0477e-01,  2.8994e-01,  8.7514e-01,  ...,  5.0688e-01,\n",
      "            8.6849e-01,  9.1033e-01],\n",
      "          [ 1.9880e-01,  5.7582e-01,  7.4301e-01,  ...,  1.9468e-01,\n",
      "            2.1573e-01,  5.4468e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2480e-01,  3.5834e-01,  1.9711e-03,  ...,  3.9400e-01,\n",
      "            3.5129e-01,  3.4995e-01],\n",
      "          [ 2.7056e-01,  5.3946e-01,  3.3928e-01,  ...,  5.5197e-01,\n",
      "           -2.0683e-01,  1.0282e-01],\n",
      "          [ 1.0397e-01,  1.3948e-01,  6.9302e-01,  ...,  5.3255e-01,\n",
      "            2.8359e-01,  1.8240e-01],\n",
      "          ...,\n",
      "          [-1.9377e-01,  6.3185e-01,  8.8592e-01,  ...,  4.5095e-01,\n",
      "            8.1602e-01,  4.6069e-01],\n",
      "          [-2.5865e-01,  2.0305e-01,  8.9709e-01,  ...,  3.9830e-01,\n",
      "            9.2749e-01,  3.6615e-01],\n",
      "          [ 1.3410e-01,  1.5891e-01,  5.8093e-01,  ...,  3.6487e-01,\n",
      "            2.6679e-02,  1.7452e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3363e-01,  6.2381e-02, -2.7020e-02,  ...,  7.4021e-01,\n",
      "            6.1496e-01,  2.9774e-01],\n",
      "          [ 9.8783e-02,  3.0305e-01,  4.4383e-01,  ...,  1.0209e+00,\n",
      "            5.8082e-01,  4.3544e-01],\n",
      "          [ 8.2873e-03, -4.8174e-02,  5.4004e-01,  ...,  5.2034e-01,\n",
      "            5.9570e-01,  4.0033e-01],\n",
      "          ...,\n",
      "          [-1.4156e-01,  8.8798e-01,  1.2062e+00,  ...,  9.0880e-01,\n",
      "            8.4228e-01,  7.9718e-01],\n",
      "          [-4.1231e-01,  2.4600e-01,  9.3973e-01,  ...,  2.6733e-01,\n",
      "            5.8941e-01,  7.7068e-01],\n",
      "          [ 1.5876e-01,  5.0581e-01,  5.9586e-01,  ...,  7.1165e-01,\n",
      "            5.7861e-01,  8.4321e-02]]]], device='cuda:1',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  11%|█         | 32/297 [03:40<55:46, 12.63s/img, loss (batch)=0.825]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1837,  0.4716,  0.5453,  ...,  0.3725,  0.4178,  0.2275],\n",
      "          [ 0.3266,  0.5072,  0.7142,  ...,  0.2751,  0.1586,  0.0704],\n",
      "          [ 0.1934,  0.2985,  0.2962,  ...,  0.3702,  0.0678,  0.3887],\n",
      "          ...,\n",
      "          [-0.0687,  0.7349,  0.6433,  ...,  0.4057,  0.2992,  0.0766],\n",
      "          [-0.2368,  0.1590,  0.6862,  ...,  0.3107,  0.3018,  0.3042],\n",
      "          [ 0.0432,  0.2536,  0.6631,  ...,  0.3699, -0.0172,  0.1963]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2594,  0.0980, -0.0356,  ...,  0.2860,  0.3837,  0.3017],\n",
      "          [ 0.0561,  0.3368,  0.4295,  ...,  0.4051,  0.3067,  0.1719],\n",
      "          [ 0.0724, -0.0728,  0.4733,  ...,  0.4556,  0.2600,  0.3144],\n",
      "          ...,\n",
      "          [-0.1461,  0.8485,  0.9576,  ...,  0.5982,  0.5023,  0.2614],\n",
      "          [-0.3794, -0.0332,  0.6994,  ...,  0.5359,  0.8339,  0.4865],\n",
      "          [ 0.1385,  0.4073,  0.4398,  ...,  0.4349,  0.2547,  0.1670]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2780,  0.0877, -0.0216,  ...,  0.3474,  0.4047,  0.2532],\n",
      "          [ 0.0699,  0.3020,  0.4009,  ...,  0.2537,  0.1529,  0.1468],\n",
      "          [ 0.0428, -0.1068,  0.4716,  ...,  0.3317,  0.0293,  0.3954],\n",
      "          ...,\n",
      "          [-0.1479,  0.7758,  0.9105,  ..., -0.1165,  0.1025,  0.6881],\n",
      "          [-0.3367, -0.0081,  0.7140,  ...,  0.3363,  0.6779,  0.7769],\n",
      "          [ 0.1359,  0.3817,  0.4037,  ...,  0.1867, -0.0262,  0.3014]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2654,  0.3520,  0.1126,  ...,  0.2943,  0.3774,  0.2380],\n",
      "          [ 0.0248,  0.4538,  0.5423,  ...,  0.3460,  0.1986,  0.1736],\n",
      "          [ 0.0399, -0.0540,  0.6304,  ...,  0.6226,  0.0783,  0.2381],\n",
      "          ...,\n",
      "          [-0.2252, -0.1289,  0.3490,  ...,  0.3750,  0.3638,  0.7062],\n",
      "          [-0.0318,  0.0392,  0.4494,  ...,  0.2213,  0.4750,  0.6332],\n",
      "          [ 0.2511,  0.2372,  0.7564,  ...,  0.4964,  0.1863,  0.1436]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  12%|█▏        | 36/297 [03:41<38:09,  8.77s/img, loss (batch)=0.761]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2881,  0.1274, -0.2432,  ...,  0.1722,  0.2647,  0.2040],\n",
      "          [ 0.0849, -0.0279,  0.5733,  ...,  0.5805,  0.0180,  0.1414],\n",
      "          [ 0.2840,  0.1264,  0.5277,  ...,  0.9659,  0.2128,  0.0888],\n",
      "          ...,\n",
      "          [-0.2914,  1.4643,  0.7731,  ...,  0.7203,  0.5439,  0.4032],\n",
      "          [-0.1780,  0.7840,  1.5022,  ...,  0.3884,  0.9395,  0.2373],\n",
      "          [ 0.0784,  0.0731,  0.2935,  ...,  0.3548,  0.1079,  0.1813]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2920,  0.1246, -0.2445,  ...,  0.1440,  0.2643,  0.2097],\n",
      "          [ 0.1076, -0.0410,  0.5820,  ...,  0.5862,  0.0120,  0.1633],\n",
      "          [ 0.2820,  0.1235,  0.5333,  ...,  0.9752,  0.1692,  0.1143],\n",
      "          ...,\n",
      "          [-0.2936,  1.4367,  0.7971,  ...,  0.4471,  0.3069,  0.2231],\n",
      "          [-0.1894,  0.7841,  1.5207,  ...,  0.6923,  0.9281,  0.6312],\n",
      "          [ 0.0776,  0.0653,  0.2733,  ...,  0.2887,  0.2458,  0.1254]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1597, -0.1046,  0.0054,  ...,  0.5158,  0.4901,  0.4899],\n",
      "          [ 0.3716,  0.6254,  0.3260,  ...,  0.4009,  0.0609, -0.0176],\n",
      "          [ 0.2825,  0.6962,  0.7884,  ...,  1.4019,  0.3989,  0.4043],\n",
      "          ...,\n",
      "          [-0.3331,  1.4051,  0.8178,  ...,  0.7087,  0.6566,  0.4817],\n",
      "          [-0.1530,  0.8968,  1.5624,  ...,  0.3498,  1.0411,  0.3302],\n",
      "          [ 0.0460,  0.0403,  0.2407,  ...,  0.3988,  0.1691,  0.2034]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1154,  0.6846,  0.5315,  ...,  0.7601,  0.7285,  0.6840],\n",
      "          [ 0.1649,  0.5423,  0.2455,  ...,  0.4485,  0.4628,  0.1586],\n",
      "          [ 0.3110,  0.2102, -0.1200,  ...,  0.6986,  0.4928,  0.1813],\n",
      "          ...,\n",
      "          [-0.2691,  0.1937,  0.4229,  ...,  0.7839,  0.5841,  0.1909],\n",
      "          [ 0.0984,  0.0304,  1.0331,  ...,  0.9310,  0.9301,  0.1527],\n",
      "          [ 0.3050,  0.2387,  0.6655,  ...,  0.4687, -0.1485,  0.0906]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  13%|█▎        | 40/297 [03:43<26:19,  6.15s/img, loss (batch)=0.578]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1870,  0.3360,  0.4796,  ...,  0.4186,  0.3803,  0.1342],\n",
      "          [ 0.3454,  0.5915,  0.5120,  ...,  0.3367,  0.2137,  0.1143],\n",
      "          [ 0.2752,  0.1981,  0.4674,  ...,  0.5771,  0.2062,  0.0988],\n",
      "          ...,\n",
      "          [-0.1707,  0.0461,  0.5153,  ...,  0.3259,  0.4884,  0.2475],\n",
      "          [-0.0589,  0.0024,  0.5954,  ...,  0.2201,  0.3634,  0.1488],\n",
      "          [ 0.1845,  0.1065,  0.4344,  ...,  0.1946,  0.0915,  0.1912]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1486,  0.3833,  0.0287,  ...,  0.2931,  0.3734,  0.1883],\n",
      "          [-0.0619,  0.2283,  0.3042,  ...,  0.0909,  0.2001,  0.0814],\n",
      "          [ 0.0752, -0.0794,  0.1763,  ...,  0.0574, -0.0280,  0.3017],\n",
      "          ...,\n",
      "          [-0.2262,  1.0405,  0.6807,  ...,  0.2876,  0.4700,  0.2040],\n",
      "          [-0.3201,  0.3218,  0.6474,  ...,  0.2548,  0.5200,  0.2472],\n",
      "          [ 0.1477,  0.5550,  0.4864,  ...,  0.1239,  0.0223,  0.1272]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1940,  0.2859,  0.0344,  ...,  0.2305,  0.3165,  0.2152],\n",
      "          [ 0.1883,  0.3475,  0.1420,  ...,  0.1551,  0.1825,  0.0024],\n",
      "          [ 0.2235,  0.1223,  0.2629,  ...,  0.2122, -0.0699,  0.1291],\n",
      "          ...,\n",
      "          [-0.0253,  0.3710,  0.6493,  ...,  0.3536,  0.0642,  0.3449],\n",
      "          [ 0.0635,  0.2992,  0.6628,  ...,  0.3939,  0.2584,  0.2397],\n",
      "          [ 0.1110,  0.2246,  0.4629,  ...,  0.3327,  0.2195,  0.2151]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0538,  0.1552,  0.0312,  ...,  0.2242,  0.3076,  0.3598],\n",
      "          [ 0.4130,  0.4630,  0.3021,  ...,  0.3002,  0.0647,  0.1676],\n",
      "          [ 0.0634,  0.1708,  0.2732,  ...,  0.5973,  0.2323,  0.1070],\n",
      "          ...,\n",
      "          [-0.2481,  1.0303,  0.6832,  ...,  0.5229,  0.1635,  0.2486],\n",
      "          [-0.3402,  0.3026,  0.6155,  ...,  0.2720,  0.5591,  0.4460],\n",
      "          [ 0.1588,  0.5655,  0.4942,  ...,  0.2354,  0.1956,  0.1852]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  15%|█▍        | 44/297 [03:44<18:20,  4.35s/img, loss (batch)=0.664]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1582,  0.1868,  0.0740,  ...,  0.1548,  0.2320,  0.2780],\n",
      "          [ 0.1498,  0.4351,  0.3947,  ...,  0.0577,  0.1067,  0.1468],\n",
      "          [ 0.1107,  0.1570,  0.2875,  ...,  0.4456,  0.2141,  0.2531],\n",
      "          ...,\n",
      "          [-0.0600,  0.3491,  0.5545,  ...,  0.4171,  0.0467,  0.2008],\n",
      "          [-0.1003,  0.0445,  0.4786,  ...,  0.1984,  0.1762,  0.4686],\n",
      "          [ 0.1279,  0.3335,  0.3844,  ...,  0.3956,  0.0842,  0.1848]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1499,  0.1272,  0.0734,  ...,  0.5244,  0.4435,  0.2097],\n",
      "          [-0.0244,  0.2549,  0.2669,  ...,  0.3878,  0.0105,  0.1646],\n",
      "          [ 0.0165, -0.0754,  0.3425,  ...,  0.4269,  0.2417,  0.0532],\n",
      "          ...,\n",
      "          [-0.1010,  0.8257,  0.7789,  ..., -0.1421, -0.0377,  0.5547],\n",
      "          [-0.3550,  0.2706,  0.5587,  ...,  0.1146,  0.3432,  0.5966],\n",
      "          [ 0.1115,  0.5364,  0.5078,  ...,  0.2316,  0.0395,  0.2631]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1395,  0.5071,  0.7060,  ...,  0.2706,  0.3326,  0.1558],\n",
      "          [ 0.1607,  0.3570,  0.7399,  ...,  0.0081,  0.2881,  0.0471],\n",
      "          [ 0.2265,  0.2676,  0.6566,  ..., -0.0716, -0.1373,  0.0867],\n",
      "          ...,\n",
      "          [-0.0611,  0.3537,  0.4581,  ...,  0.1277,  0.1157,  0.0758],\n",
      "          [ 0.0475,  0.0380,  0.5816,  ...,  0.4255,  0.3885,  0.2496],\n",
      "          [ 0.1441,  0.4734,  0.6295,  ...,  0.2116,  0.1297,  0.1681]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1651,  0.1972,  0.0723,  ...,  0.5828,  0.5417,  0.1291],\n",
      "          [-0.0566,  0.2731,  0.3270,  ...,  0.3979,  0.4378,  0.2119],\n",
      "          [-0.0360,  0.0076,  0.3480,  ...,  0.1926,  0.3717,  0.3040],\n",
      "          ...,\n",
      "          [-0.1490,  0.9387,  0.7771,  ...,  0.3656,  0.3437,  0.2094],\n",
      "          [-0.3597,  0.2963,  0.5386,  ...,  0.0485,  0.2661,  0.2017],\n",
      "          [ 0.1436,  0.5452,  0.5701,  ...,  0.5014,  0.3333,  0.2043]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  16%|█▌        | 48/297 [03:45<12:53,  3.11s/img, loss (batch)=0.613]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2061,  0.4463,  0.2712,  ...,  0.2656,  0.3952,  0.2163],\n",
      "          [ 0.3021,  0.5067,  0.4719,  ...,  0.3730,  0.3449,  0.1204],\n",
      "          [ 0.4807,  0.0055,  0.1128,  ...,  0.7738,  0.5439,  0.2216],\n",
      "          ...,\n",
      "          [-0.2659,  0.4680,  0.4326,  ...,  0.5245,  0.5506,  0.2473],\n",
      "          [ 0.1384,  0.2782,  0.6167,  ...,  0.5830,  0.5856,  0.3457],\n",
      "          [ 0.2220,  0.4091,  0.7186,  ...,  0.4570,  0.1822,  0.2875]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1684,  0.1945, -0.0116,  ...,  0.3271,  0.3300,  0.2801],\n",
      "          [ 0.1365,  0.3539,  0.3900,  ...,  0.4231,  0.2150,  0.1967],\n",
      "          [ 0.2424,  0.2097,  0.4660,  ...,  0.6065,  0.1489,  0.2183],\n",
      "          ...,\n",
      "          [-0.3956,  0.7210,  0.6934,  ...,  0.4930,  0.8648,  0.6294],\n",
      "          [-0.1564,  0.2023,  0.9631,  ...,  0.5128,  0.6752,  0.5258],\n",
      "          [-0.0788,  0.1072,  0.4091,  ...,  0.3485,  0.3457,  0.2123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2097,  0.6085,  0.6926,  ...,  0.7579,  0.6194,  0.6053],\n",
      "          [ 0.4318,  1.1812,  0.8569,  ...,  0.7139,  0.4141,  0.1001],\n",
      "          [ 0.4241,  0.5938,  0.6354,  ...,  0.9644,  0.5650,  0.4568],\n",
      "          ...,\n",
      "          [-0.2519,  0.7171,  0.6079,  ...,  0.5813,  0.4379,  0.3929],\n",
      "          [-0.0359,  0.3339,  0.9925,  ...,  0.6175,  0.5160,  0.3720],\n",
      "          [-0.0434,  0.2328,  0.3903,  ...,  0.4695,  0.4159,  0.1501]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1558,  0.1848, -0.0443,  ...,  0.4881,  0.4049,  0.3372],\n",
      "          [ 0.1857,  0.4368,  0.4360,  ...,  0.3683,  0.1543,  0.0318],\n",
      "          [ 0.2130,  0.2580,  0.4985,  ...,  0.9889,  0.4342,  0.2281],\n",
      "          ...,\n",
      "          [-0.4178,  0.7188,  0.6803,  ...,  0.3785,  0.3276,  0.4310],\n",
      "          [-0.1435,  0.2445,  1.0025,  ...,  0.3956,  0.8767,  0.4357],\n",
      "          [-0.0883,  0.0691,  0.3856,  ...,  0.3811, -0.0402,  0.1114]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  18%|█▊        | 52/297 [03:46<09:12,  2.26s/img, loss (batch)=0.8]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.1615e-01,  1.7720e-01,  4.9799e-02,  ...,  2.1371e-01,\n",
      "            3.0188e-01,  1.7027e-01],\n",
      "          [ 3.9896e-02,  2.5359e-01,  2.9767e-01,  ...,  2.2561e-01,\n",
      "            2.6256e-01,  7.3277e-02],\n",
      "          [ 1.3442e-01,  4.1055e-02,  2.8179e-01,  ...,  2.3052e-01,\n",
      "            1.0507e-01,  1.2526e-01],\n",
      "          ...,\n",
      "          [-5.8341e-02,  5.6703e-01,  3.6577e-01,  ..., -8.6760e-02,\n",
      "            8.4568e-04,  4.2700e-01],\n",
      "          [-1.2598e-01,  1.3253e-01,  3.6427e-01,  ...,  4.8591e-02,\n",
      "            2.8047e-01,  3.1022e-01],\n",
      "          [ 9.2368e-02,  2.2196e-01,  2.9824e-01,  ...,  1.7620e-01,\n",
      "            5.7399e-02,  1.3647e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9197e-01,  9.4523e-02,  8.3429e-02,  ...,  2.4503e-01,\n",
      "            2.4933e-01,  2.8505e-01],\n",
      "          [-9.8291e-03,  4.7854e-01,  3.4764e-01,  ...,  5.2222e-02,\n",
      "            2.1297e-01,  1.0809e-01],\n",
      "          [ 6.9323e-02,  7.6375e-02,  2.4970e-01,  ...,  3.7870e-01,\n",
      "            1.4935e-01,  9.0398e-02],\n",
      "          ...,\n",
      "          [-4.6272e-02,  4.9355e-01,  3.1264e-01,  ...,  1.9249e-01,\n",
      "            3.7937e-01,  1.9065e-01],\n",
      "          [-9.5624e-02,  3.5090e-01,  5.5827e-01,  ...,  3.6618e-01,\n",
      "            3.9812e-01,  2.9396e-01],\n",
      "          [ 4.1022e-02,  2.3822e-01,  3.0513e-01,  ...,  2.9105e-01,\n",
      "            2.7567e-01,  1.6432e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3158e-01,  1.2134e-01,  7.2547e-02,  ...,  7.8737e-02,\n",
      "            1.7802e-01,  1.4546e-01],\n",
      "          [ 2.1476e-01,  3.4282e-01,  1.4870e-01,  ...,  2.1582e-01,\n",
      "            2.3360e-01,  5.3427e-03],\n",
      "          [ 1.2160e-01,  1.9022e-01,  4.1916e-01,  ...,  2.1647e-01,\n",
      "           -5.2579e-02,  6.9268e-02],\n",
      "          ...,\n",
      "          [-8.6863e-02,  5.7732e-01,  3.4598e-01,  ...,  3.5657e-02,\n",
      "            1.3246e-01,  3.4941e-01],\n",
      "          [-8.5324e-02,  2.1702e-01,  5.6130e-01,  ...,  1.7108e-01,\n",
      "            4.0153e-01,  3.1384e-01],\n",
      "          [ 8.4726e-02,  2.0856e-01,  3.3396e-01,  ...,  1.2605e-01,\n",
      "           -1.9073e-02,  9.0786e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1145e-01,  5.4077e-01,  5.7657e-01,  ...,  6.7414e-01,\n",
      "            2.4616e-01,  2.0180e-01],\n",
      "          [ 2.4874e-01,  8.9490e-01,  7.9837e-01,  ...,  4.9619e-01,\n",
      "            3.3386e-01,  1.0107e-01],\n",
      "          [ 2.7280e-01,  7.3971e-01,  9.1190e-01,  ...,  9.3458e-01,\n",
      "            4.9580e-01,  2.0856e-01],\n",
      "          ...,\n",
      "          [ 5.5192e-03,  2.4429e-01,  5.8134e-01,  ...,  8.1451e-01,\n",
      "            8.7037e-01,  4.0835e-01],\n",
      "          [ 1.4675e-01,  8.4386e-02,  6.2841e-01,  ...,  4.6270e-01,\n",
      "            5.0797e-01,  2.5587e-01],\n",
      "          [ 2.2772e-01,  4.1402e-01,  5.3100e-01,  ...,  3.6107e-01,\n",
      "            1.5251e-01,  1.7235e-01]]]], device='cuda:1',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  19%|█▉        | 56/297 [03:47<06:43,  1.68s/img, loss (batch)=0.8]INFO: item_loss: 11.442192375659943\n",
      "\n",
      "Validation round:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  12%|█▎        | 1/8 [00:20<02:26, 20.97s/batch]\u001b[A\n",
      "Validation round:  25%|██▌       | 2/8 [00:21<00:52,  8.80s/batch]\u001b[A\n",
      "Validation round:  38%|███▊      | 3/8 [00:21<00:24,  4.92s/batch]\u001b[A\n",
      "Validation round:  50%|█████     | 4/8 [00:36<00:35,  8.86s/batch]\u001b[A\n",
      "Validation round:  62%|██████▎   | 5/8 [00:36<00:17,  5.78s/batch]\u001b[A\n",
      "Validation round:  75%|███████▌  | 6/8 [00:37<00:07,  3.92s/batch]\u001b[A\n",
      "Validation round:  88%|████████▊ | 7/8 [00:37<00:02,  2.74s/batch]\u001b[A\n",
      "Validation round: 100%|██████████| 8/8 [00:37<00:00,  1.96s/batch]\u001b[A\n",
      "                                                                  \u001b[AINFO: lr: 0.0001\n",
      "INFO: Validation Dice Coeff: 0.14267691513746977\n",
      "Epoch 1/20:  19%|█▉        | 56/297 [04:34<06:43,  1.68s/img, loss (batch)=0.734]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.0707e-01,  2.3786e-01,  5.8298e-02,  ...,  3.2773e-01,\n",
      "            2.4264e-01,  3.6899e-01],\n",
      "          [ 1.1418e-01,  5.0255e-01,  4.4933e-01,  ...,  6.5371e-01,\n",
      "            2.6806e-01,  2.0784e-01],\n",
      "          [ 2.2828e-01,  3.3514e-01,  3.6147e-01,  ...,  8.5268e-01,\n",
      "            3.7586e-01,  3.5922e-01],\n",
      "          ...,\n",
      "          [-3.7697e-01,  5.6081e-01,  5.0608e-01,  ...,  4.3123e-01,\n",
      "            1.7589e-01,  3.4855e-01],\n",
      "          [-1.0713e-01,  2.1816e-01,  1.0260e+00,  ...,  4.3955e-01,\n",
      "            8.5332e-01,  3.6945e-01],\n",
      "          [-5.1238e-02,  2.3707e-01,  4.9972e-01,  ...,  3.0893e-01,\n",
      "            4.0377e-02,  1.4369e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5669e-01,  2.3583e-01,  8.3595e-02,  ...,  5.9014e-01,\n",
      "            5.8291e-01,  1.8544e-01],\n",
      "          [ 4.1547e-02,  3.0786e-01,  2.9934e-01,  ...,  4.8662e-01,\n",
      "            4.6246e-01,  2.5793e-01],\n",
      "          [ 2.2430e-01,  2.8933e-01,  2.6739e-01,  ...,  7.8812e-01,\n",
      "            2.4952e-01,  2.1792e-01],\n",
      "          ...,\n",
      "          [-4.3529e-01,  6.0444e-01,  4.3472e-01,  ...,  5.6183e-01,\n",
      "            3.7063e-01,  2.0471e-01],\n",
      "          [-1.2876e-01,  2.0664e-01,  9.9743e-01,  ...,  5.4564e-01,\n",
      "            1.1128e+00,  3.6888e-01],\n",
      "          [-8.7837e-02,  5.4063e-02,  4.3075e-01,  ...,  2.7650e-01,\n",
      "            1.3114e-01,  1.5731e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3472e-01,  4.2736e-01,  3.6671e-01,  ...,  4.6817e-01,\n",
      "            7.1472e-01,  4.6765e-01],\n",
      "          [ 3.2481e-01,  9.2438e-01,  4.5371e-01,  ...,  1.5846e-01,\n",
      "            5.3844e-01,  1.4764e-02],\n",
      "          [ 2.2604e-01,  5.8952e-01,  7.2246e-01,  ...,  9.0588e-01,\n",
      "            9.2490e-01,  5.8708e-01],\n",
      "          ...,\n",
      "          [-1.0898e-02,  3.5096e-01,  7.4537e-01,  ...,  1.1513e+00,\n",
      "            6.3827e-01,  3.6626e-01],\n",
      "          [ 1.1760e-01, -6.2109e-02,  9.5743e-01,  ...,  4.4427e-01,\n",
      "            8.2637e-01,  3.6021e-01],\n",
      "          [ 2.9507e-01,  2.7425e-01,  6.2919e-01,  ...,  7.4944e-01,\n",
      "            4.0936e-01,  3.3148e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2146e-01,  2.3969e-01,  6.5492e-02,  ...,  3.7182e-01,\n",
      "            2.6591e-01,  3.9669e-01],\n",
      "          [ 9.0484e-02,  4.6013e-01,  3.7564e-01,  ...,  6.9911e-01,\n",
      "            3.1173e-01,  2.1518e-01],\n",
      "          [ 2.1232e-01,  3.2775e-01,  3.5088e-01,  ...,  7.9031e-01,\n",
      "            4.1479e-01,  3.2399e-01],\n",
      "          ...,\n",
      "          [-4.1263e-01,  4.8860e-01,  2.6903e-01,  ...,  3.1879e-01,\n",
      "            1.3238e-01,  3.2566e-01],\n",
      "          [-3.1532e-01,  3.0110e-01,  8.1469e-01,  ...,  4.4644e-01,\n",
      "            8.1232e-01,  3.6540e-01],\n",
      "          [ 5.7700e-02,  3.5564e-01,  3.9918e-01,  ...,  3.2102e-01,\n",
      "           -2.1424e-04,  1.3711e-01]]]], device='cuda:1',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  20%|██        | 60/297 [04:35<18:49,  4.76s/img, loss (batch)=0.564]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 7.1599e-02,  2.5287e-01,  7.6776e-02,  ..., -1.3044e-01,\n",
      "            1.9446e-01,  1.0863e-01],\n",
      "          [-1.7693e-01,  2.5206e-01,  3.7919e-01,  ..., -2.8828e-01,\n",
      "            5.3159e-04,  4.5894e-02],\n",
      "          [-3.3538e-02, -1.4676e-01,  2.8225e-01,  ..., -3.5880e-01,\n",
      "           -3.4798e-01,  3.6566e-02],\n",
      "          ...,\n",
      "          [-5.0635e-02,  3.2028e-01,  1.5637e-01,  ...,  7.9801e-02,\n",
      "            2.7843e-01,  1.8776e-01],\n",
      "          [-3.4380e-02,  1.8947e-01,  2.8956e-01,  ...,  1.2655e-01,\n",
      "            3.4026e-01,  2.2177e-01],\n",
      "          [ 1.7257e-01,  3.9116e-01,  4.2913e-01,  ..., -6.4814e-03,\n",
      "            9.3032e-02,  7.2619e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0681e-02,  8.6259e-02,  8.4183e-02,  ...,  3.5074e-01,\n",
      "            4.3296e-01,  2.8588e-01],\n",
      "          [-6.5742e-02,  2.1916e-01,  4.3234e-01,  ...,  2.0646e-01,\n",
      "            5.0304e-01,  2.5935e-01],\n",
      "          [-3.4335e-02, -1.4293e-01,  1.8954e-01,  ...,  3.9295e-01,\n",
      "            2.8644e-01,  2.8681e-01],\n",
      "          ...,\n",
      "          [-5.6104e-02,  3.6354e-01,  2.5612e-01,  ...,  4.5790e-01,\n",
      "            1.1520e+00,  4.6148e-01],\n",
      "          [-8.3117e-02,  4.7712e-02,  3.9850e-01,  ...,  4.9753e-01,\n",
      "            9.2857e-01,  5.0308e-01],\n",
      "          [-2.1534e-02, -1.2573e-02,  3.4866e-01,  ...,  3.8908e-01,\n",
      "            3.7300e-01,  1.8781e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9123e-02,  3.4998e-01,  3.5338e-01,  ..., -9.1061e-02,\n",
      "           -3.3765e-02,  5.1381e-02],\n",
      "          [ 1.2744e-01,  3.2184e-01,  3.0373e-01,  ..., -3.3547e-01,\n",
      "           -1.3148e-01, -6.2331e-02],\n",
      "          [ 1.0959e-01,  2.5448e-01,  3.2383e-01,  ...,  6.0241e-02,\n",
      "            2.9063e-01,  2.4354e-01],\n",
      "          ...,\n",
      "          [-8.6580e-02,  4.2885e-01,  1.8313e-01,  ...,  5.9498e-02,\n",
      "            1.3643e-01,  1.1054e-01],\n",
      "          [-5.2589e-02,  2.9570e-01,  3.9531e-01,  ...,  9.2359e-02,\n",
      "            1.3695e-01,  1.3373e-01],\n",
      "          [ 1.2829e-01,  3.5038e-01,  4.9279e-01,  ...,  2.2834e-01,\n",
      "            1.1856e-01,  1.2741e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0906e-01,  3.4425e-01,  2.2014e-01,  ...,  3.3047e-01,\n",
      "            3.8352e-01,  2.2947e-01],\n",
      "          [ 2.8186e-01,  4.3248e-01,  5.7243e-01,  ...,  1.1463e-01,\n",
      "            2.9543e-01,  2.0099e-01],\n",
      "          [ 2.6768e-01,  1.7933e-01,  5.5139e-01,  ...,  3.3842e-01,\n",
      "            1.8170e-01,  2.5108e-01],\n",
      "          ...,\n",
      "          [-1.0494e-02,  2.7152e-01,  3.9343e-01,  ...,  2.1264e-01,\n",
      "            2.4065e-01,  1.0050e-01],\n",
      "          [ 1.3232e-01,  1.1673e-01,  5.2911e-01,  ...,  2.6082e-01,\n",
      "            3.2134e-01,  2.4896e-01],\n",
      "          [ 2.0396e-01,  1.4205e-01,  4.9108e-01,  ...,  2.5210e-01,\n",
      "            1.3946e-01,  1.8986e-01]]]], device='cuda:1',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  22%|██▏       | 64/297 [04:36<13:15,  3.41s/img, loss (batch)=0.606]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1603,  0.4493,  0.5009,  ...,  0.1685,  0.2810,  0.1582],\n",
      "          [ 0.3547,  0.8976,  0.8438,  ...,  0.1715,  0.2770,  0.0408],\n",
      "          [ 0.3682,  0.6191,  0.5665,  ...,  0.1005,  0.0952,  0.0380],\n",
      "          ...,\n",
      "          [ 0.0340,  0.4186,  0.4528,  ...,  0.1562,  0.2020,  0.1506],\n",
      "          [-0.1020,  0.0071,  0.4147,  ...,  0.2403,  0.5072,  0.4034],\n",
      "          [-0.0306,  0.1602,  0.3950,  ...,  0.2564,  0.0439,  0.0712]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1879,  0.2985,  0.0914,  ...,  0.0728,  0.1351,  0.1988],\n",
      "          [ 0.1995,  0.6865,  0.2732,  ...,  0.3383,  0.2113,  0.1323],\n",
      "          [ 0.2479,  0.3762,  0.5471,  ...,  0.4399,  0.0817,  0.1429],\n",
      "          ...,\n",
      "          [-0.0740,  0.2818,  0.3534,  ...,  0.3438,  0.4303,  0.2458],\n",
      "          [-0.0982,  0.0247,  0.6840,  ...,  0.2856,  0.4306,  0.3005],\n",
      "          [ 0.0246,  0.2454,  0.3857,  ...,  0.3629,  0.2972,  0.2613]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1868,  0.1738,  0.1327,  ...,  0.1775,  0.3175,  0.1724],\n",
      "          [-0.0629,  0.1518,  0.1562,  ...,  0.0252,  0.2650,  0.0053],\n",
      "          [ 0.1230,  0.0864,  0.2582,  ...,  0.0601,  0.0661,  0.0445],\n",
      "          ...,\n",
      "          [-0.1408,  0.3603,  0.2468,  ...,  0.2999,  0.5093,  0.3152],\n",
      "          [-0.0483, -0.0142,  0.4799,  ...,  0.0588,  0.4357,  0.2337],\n",
      "          [ 0.0681,  0.0553,  0.4113,  ...,  0.3015,  0.3960,  0.3115]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1508,  0.1947,  0.1467,  ...,  0.3179,  0.3694,  0.1802],\n",
      "          [ 0.1191,  0.6571,  0.1930,  ...,  0.0363,  0.1191,  0.1503],\n",
      "          [ 0.2133,  0.1090,  0.3661,  ...,  0.1544,  0.1645,  0.2204],\n",
      "          ...,\n",
      "          [-0.1379,  0.4777,  0.4639,  ..., -0.1017,  0.0468,  0.1486],\n",
      "          [-0.1057,  0.1296,  0.6947,  ...,  0.2179,  0.4709,  0.4011],\n",
      "          [ 0.1117,  0.3366,  0.5721,  ...,  0.2702,  0.0858,  0.1407]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  23%|██▎       | 68/297 [04:38<09:25,  2.47s/img, loss (batch)=1]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1277,  0.3311,  0.2191,  ...,  0.3823,  0.3082,  0.2035],\n",
      "          [ 0.3507,  0.6421,  0.6067,  ...,  0.3132,  0.2297,  0.0803],\n",
      "          [ 0.2807,  0.2917,  0.4023,  ...,  0.4291,  0.2594,  0.0945],\n",
      "          ...,\n",
      "          [ 0.0374,  0.3637,  0.8378,  ...,  0.5769,  0.5990,  0.3889],\n",
      "          [ 0.0627,  0.2549,  1.0438,  ...,  0.4431,  0.6031,  0.4118],\n",
      "          [ 0.2047,  0.2999,  0.7021,  ...,  0.3080,  0.1303,  0.1158]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1380,  0.3938,  0.5999,  ...,  0.7414,  0.8127,  0.7387],\n",
      "          [ 0.3842,  0.5326,  0.6662,  ...,  0.7803,  0.4889,  0.3268],\n",
      "          [ 0.3031,  0.2702,  0.2822,  ...,  0.6981,  0.7084,  0.4734],\n",
      "          ...,\n",
      "          [-0.1295,  0.4027,  0.1520,  ..., -0.1123,  0.0423,  0.2181],\n",
      "          [-0.1387,  0.0811,  0.4903,  ...,  0.0680,  0.3591,  0.2651],\n",
      "          [ 0.0665,  0.0529,  0.2595,  ...,  0.0843,  0.0093,  0.1051]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1200,  0.2848,  0.1317,  ...,  0.2073,  0.1627,  0.1087],\n",
      "          [-0.0485,  0.3507,  0.3046,  ...,  0.0951,  0.0953,  0.0531],\n",
      "          [ 0.0192,  0.1599,  0.2498,  ...,  0.2311,  0.1661,  0.0622],\n",
      "          ...,\n",
      "          [-0.1013,  0.4733,  0.4068,  ..., -0.1466,  0.0236,  0.2790],\n",
      "          [-0.1100,  0.1890,  0.6369,  ...,  0.1129,  0.3543,  0.3110],\n",
      "          [ 0.1498,  0.3039,  0.2279,  ...,  0.0944,  0.0416,  0.1203]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1042,  0.2436,  0.0340,  ...,  0.1314,  0.2104,  0.1174],\n",
      "          [-0.0828,  0.3292,  0.2629,  ...,  0.0956,  0.1386,  0.0038],\n",
      "          [ 0.0466,  0.0581,  0.3263,  ..., -0.0739, -0.0304,  0.0829],\n",
      "          ...,\n",
      "          [-0.0685,  0.3377,  0.6600,  ..., -0.1162,  0.0311,  0.2401],\n",
      "          [ 0.1791,  0.1584,  0.7983,  ...,  0.0851,  0.3605,  0.2650],\n",
      "          [ 0.2352,  0.3303,  0.6599,  ...,  0.1022,  0.0207,  0.1129]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  24%|██▍       | 72/297 [04:39<07:01,  1.87s/img, loss (batch)=0.583]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1912,  0.5747,  0.6418,  ...,  0.5521,  0.5317,  0.2634],\n",
      "          [ 0.4225,  0.8527,  0.9201,  ...,  0.5572,  0.4584,  0.2437],\n",
      "          [ 0.4414,  0.7303,  0.9276,  ...,  0.6160,  0.5187,  0.2758],\n",
      "          ...,\n",
      "          [-0.1122,  0.3959,  0.0882,  ..., -0.0996,  0.0264,  0.1440],\n",
      "          [-0.1490, -0.0068,  0.2983,  ...,  0.1301,  0.4054,  0.3082],\n",
      "          [ 0.0840,  0.0960,  0.2170,  ...,  0.0843,  0.0140,  0.0807]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0563,  0.1934,  0.0422,  ...,  0.1842,  0.1324,  0.1235],\n",
      "          [ 0.1546,  0.4521,  0.2820,  ...,  0.2278,  0.2079,  0.0335],\n",
      "          [ 0.2391,  0.1389,  0.2679,  ...,  0.1196, -0.0336, -0.0620],\n",
      "          ...,\n",
      "          [ 0.1486,  0.3956,  0.5301,  ...,  0.2457,  0.2309,  0.1282],\n",
      "          [ 0.0405,  0.0728,  0.6424,  ...,  0.2146,  0.3583,  0.2570],\n",
      "          [ 0.2058,  0.3544,  0.5207,  ...,  0.3534,  0.0925,  0.1440]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1769,  0.2401,  0.0688,  ...,  0.1678,  0.1696,  0.1703],\n",
      "          [ 0.1566,  0.5493,  0.3664,  ...,  0.2739,  0.1451,  0.0873],\n",
      "          [ 0.2026,  0.2010,  0.1563,  ...,  0.0236, -0.0250,  0.0154],\n",
      "          ...,\n",
      "          [-0.1084,  0.3709,  0.1147,  ..., -0.1325,  0.0056,  0.1530],\n",
      "          [-0.1462, -0.0191,  0.3453,  ...,  0.1290,  0.3868,  0.2934],\n",
      "          [ 0.1042,  0.0466,  0.2465,  ...,  0.0726,  0.0280,  0.0855]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1180,  0.1806,  0.0222,  ...,  0.1925,  0.2223,  0.1446],\n",
      "          [-0.1022,  0.3419,  0.1673,  ...,  0.1585,  0.1921,  0.0643],\n",
      "          [ 0.0551,  0.0190,  0.0919,  ..., -0.0389,  0.0014,  0.0589],\n",
      "          ...,\n",
      "          [-0.1011,  0.3726,  0.1265,  ...,  0.7996,  0.5904,  0.3498],\n",
      "          [-0.1400, -0.0111,  0.3566,  ...,  0.7245,  0.7120,  0.3925],\n",
      "          [ 0.1101,  0.0333,  0.2503,  ...,  0.3742,  0.2377,  0.2018]]]],\n",
      "       device='cuda:1', grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  26%|██▌       | 76/297 [04:58<14:27,  3.92s/img, loss (batch)=0.583]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-e3dd44e415e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    295\u001b[0m                   \u001b[0mimg_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                   val_percent=args.val / 100)\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-e3dd44e415e4>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, device, epochs, batch_size, lr, val_percent, save_cp, criterion, img_scale)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Epoch {epoch + 1}/{epochs}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/disk1/HanShihao/hsh/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/disk1/HanShihao/hsh/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/disk1/HanShihao/hsh/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-e3dd44e415e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    296\u001b[0m                   val_percent=args.val / 100)\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'INTERRUPTED.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved interrupt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# version 1 mile\n",
    "# refer : https://github.com/milesial/Pytorch-UNet/blob/master/train.py\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import cv2\n",
    "import model.model as model\n",
    "from eval import eval_net\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from augment import AUGMENTATIONS_TRAIN,AUGMENTATIONS_TEST\n",
    "Image.MAX_IMAGE_PIXELS=None\n",
    "\n",
    "'''\n",
    "from eval import eval_net\n",
    "from unet import UNet\n",
    "from utils.dataset import BasicDataset\n",
    "'''\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "dir_checkpoint= \"./check_point/\"\n",
    "\n",
    "train_mask_dir = \"../Colonoscopy_tissue_segment_dataset/train_mask\" #create  train mask\n",
    "train_dir = \"../Colonoscopy_tissue_segment_dataset/train\" # create train data\n",
    "val_mask_dir = \"../Colonoscopy_tissue_segment_dataset/val_mask\"\n",
    "val_dir = \"../Colonoscopy_tissue_segment_dataset/val\"\n",
    "\n",
    "\n",
    "class BasicDataset(Dataset):\n",
    "    def __init__(self, imgs_dir, masks_dir, preprocess=None, scale=512, mask_suffix='_mask'):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        #self.scale = scale\n",
    "        self.preprocess= preprocess\n",
    "        self.scale = scale\n",
    "        self.mask_suffix = mask_suffix\n",
    "        self.ids = [os.path.splitext(file)[0] for file in os.listdir(imgs_dir)\n",
    "                    if not file.startswith('.')]   # get prefix or so-called id\n",
    "        logging.info(f'Creating dataset with {len(self.ids)} examples')\n",
    "        #print(\"image_directory:{}  with {} files.\\nmask_dir:{}\".format(imgs_dir,len(self.ids),masks_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @classmethod\n",
    "    def process(cls, pil_img,pil_mask,preprocess=None):\n",
    "        img = np.array(pil_img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        mask = np.array(pil_mask)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
    "        if preprocess!= None:\n",
    "            transformed = preprocess(image=img,mask=mask)\n",
    "            img= transformed['image']\n",
    "            mask= transformed['mask']\n",
    "\n",
    "        img_trans = img.transpose((2, 0, 1))\n",
    "        if img_trans.max() > 1:\n",
    "            img_trans = img_trans / 255\n",
    "        #mask_trans = mask.transpose((2,0,1))\n",
    "        #print(mask.shape)\n",
    "        Grayimg = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask_trans = cv2.threshold(Grayimg, 12, 255,cv2.THRESH_BINARY)\n",
    "        #cv2.imshow(\"sss\",opencvImage)\n",
    "        _ = {\n",
    "            'image': torch.from_numpy(img_trans).type(torch.FloatTensor),\n",
    "            'mask': torch.from_numpy(mask_trans).type(torch.FloatTensor).unsqueeze(0)\n",
    "        }\n",
    "\n",
    "\n",
    "        return _\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.ids[i]\n",
    "        temp = os.path.join(self.masks_dir,idx+self.mask_suffix+'.*')\n",
    "        mask_file = glob.glob(temp)\n",
    "\n",
    "        img_file = glob.glob(os.path.join(self.imgs_dir , idx + '.*'))\n",
    "\n",
    "        assert len(mask_file) == 1, \\\n",
    "            f'Either no mask or multiple masks found for the ID {idx}: {mask_file}'\n",
    "        assert len(img_file) == 1, \\\n",
    "            f'Either no image or multiple images found for the ID {idx}: {img_file}'\n",
    "        mask = Image.open(mask_file[0])\n",
    "        img = Image.open(img_file[0])\n",
    "\n",
    "        assert img.size == mask.size, \\\n",
    "            f'Image and mask {idx} should be the same size, but are {img.size} and {mask.size}'\n",
    "        #show_img(img)\n",
    "        #img = self.process(img)\n",
    "        #mask = self.process(mask)\n",
    "\n",
    "        '''\n",
    "        mask_trans = mask.transpose((2, 0, 1))\n",
    "        if mask_trans.max() > 1:\n",
    "            mask_trans = mask_trans / 255\n",
    "        '''\n",
    "        _ =  self.process(img,mask, self.preprocess)\n",
    "        #print(\"mask shape\",_['mask'].shape)\n",
    "       # print(\"mask tensor\",_['mask'])\n",
    "        #print(\"image shape\",_['image'].shape)\n",
    "        return _\n",
    "    \n",
    "def train_net(net,\n",
    "              device,\n",
    "              epochs=10,\n",
    "              batch_size=1,\n",
    "              lr=0.001,\n",
    "              val_percent=0.1,\n",
    "              save_cp=True,\n",
    "              criterion=\"dice\",\n",
    "              img_scale=512):\n",
    "\n",
    "    #dataset = BasicDataset(train_dir, train_mask_dir, img_scale)\n",
    "    dataset = BasicDataset(train_dir, train_mask_dir,AUGMENTATIONS_TRAIN,img_scale)\n",
    "    dataset2 = BasicDataset(val_dir,val_mask_dir,AUGMENTATIONS_TEST)\n",
    "    n_train=len(dataset)\n",
    "    n_val = len(dataset2)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    val_loader = DataLoader(dataset2, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
    "\n",
    "    writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_SCALE_{img_scale}')\n",
    "    global_step = 0\n",
    "    # 基本信息\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Criterion:       {criterion}\n",
    "        Learning rate:   {lr}\n",
    "        Training size:   {len(dataset)}\n",
    "        Validation size: {len(dataset2)}\n",
    "        Checkpoints:     {save_cp}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "    ''')\n",
    "    #优化器\n",
    "#    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr,  weight_decay=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.outc > 1 else 'max', patience=8)\n",
    "    #if net.outc > 1:\n",
    "    def dice_loss(input , target):\n",
    "        input = torch.sigmoid(input)\n",
    "        smooth = 0.00001\n",
    "        iflat = input.view(-1)\n",
    "        tflat = target.view(-1)\n",
    "        intersection = (iflat * tflat).sum()\n",
    "        return 1-((2.0*intersection + smooth)/(iflat.sum()+tflat.sum()+smooth))\n",
    "    if  criterion==\"bce\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    elif criterion ==  \"cross\":\n",
    "        criterion == nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = dice_loss\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                imgs = batch['image']\n",
    "                true_masks = batch['mask']/255\n",
    "                #true_masks =batch['mask']\n",
    "                assert imgs.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "                #mask_type = torch.float32 if net.outc == 1 else torch.long\n",
    "                mask_type = torch.float32\n",
    "                true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "                #print(\"true mask shape: %s \" % true_masks.shape)\n",
    "                masks_pred = net(imgs)\n",
    "                print(masks_pred)\n",
    "                #print(\"predict mask shape:%s\" % mask_pred.shape)\n",
    "                loss = criterion(masks_pred,true_masks)\n",
    "                epoch_loss += loss.item()\n",
    "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
    "                optimizer.step()\n",
    "\n",
    "                pbar.update(imgs.shape[0])\n",
    "                global_step += 1\n",
    "                if global_step % (n_train // (10 * batch_size)) == 0:\n",
    "                    logging.info('item_loss: {}'.format(epoch_loss))\n",
    "                    for tag, value in net.named_parameters():\n",
    "                        tag = tag.replace('.', '/')\n",
    "                        writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)\n",
    "                        writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_step)\n",
    "                    val_score = eval_net(net, val_loader, device)\n",
    "                    scheduler.step(val_score)\n",
    "                    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "                    logging.info('lr: {}'.format(optimizer.param_groups[0]['lr']))\n",
    "                    if net.n_classes > 1:\n",
    "                        logging.info('Validation cross entropy: {}'.format(val_score))\n",
    "                        writer.add_scalar('Loss/test', val_score, global_step)\n",
    "                    else:\n",
    "                        logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
    "                        writer.add_scalar('Dice/test', val_score, global_step)\n",
    "\n",
    "                    writer.add_images('images', imgs, global_step)\n",
    "                    if net.n_classes == 1:\n",
    "                        writer.add_images('masks/true', true_masks, global_step)\n",
    "                        writer.add_images('masks/pred', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
    "\n",
    "        if save_cp:\n",
    "            try:\n",
    "                os.mkdir(dir_checkpoint)\n",
    "                logging.info('Created checkpoint directory')\n",
    "            except OSError:\n",
    "                pass\n",
    "            torch.save(net.state_dict(),\n",
    "                       dir_checkpoint + f'{args.net}batch{args.batchsize}scale{args.scale}epoch{epoch + 1}.pth')\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved !')\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('-e', '--epochs', metavar='E', type=int, default=20,\n",
    "                        help='Number of epochs', dest='epochs')\n",
    "    parser.add_argument('-n', '--net' ,dest=\"net\",type=str,default=\"unet\",\n",
    "                        help=\"choose net like resnet\")\n",
    "    parser.add_argument('-b', '--batch-size', metavar='B', type=int, nargs='?', default=4,\n",
    "                        help='Batch size', dest='batchsize')\n",
    "    parser.add_argument('-l', '--learning-rate', metavar='LR', type=float, nargs='?', default=0.0001,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('-f', '--load', dest='load', type=str, default=False,\n",
    "                        help='Load model from a .pth file')\n",
    "    parser.add_argument('-s', '--scale', dest='scale', type=float, default=256,\n",
    "                        help='Downscaling factor of the images')\n",
    "    parser.add_argument('-v', '--validation', dest='val', type=float, default=10.0,\n",
    "                        help='Percent of the data that is used as validation (0-100)')\n",
    "    parser.add_argument('-c', '--criterion', dest='criterion',type=str,default='dice',\n",
    "                        help = \"criterion like bce crossentropyloss, dice_loss\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "    args = get_args()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device =torch.device(\"cuda:1\")\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    # Change here to adapt to your data\n",
    "    # n_channels=3 for RGB images\n",
    "    # n_classes is the number of probabilities you want to get per pixel\n",
    "    #   - For 1 class and background, use n_classes=1\n",
    "    #   - For 2 classes, use n_classes=1\n",
    "    #   - For N > 2 classes, use n_classes=N\n",
    "    args.net=\"nested_unet\"\n",
    "    args.load=\"./check_point/nested_unetbatch4scale512.0epoch15.pth\"\n",
    "    net =  model.choose_net(args.net)\n",
    "    net = net(in_channel=3,out_channel=1)\n",
    "    logging.info(f'Network:\\n'\n",
    "                f'\\t{net.n_channels} input channels\\n'\n",
    "                 f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "                 f'\\t{\"Bilinear\" if args.load else \"Transposed conv\"} upscaling')\n",
    "\n",
    "    if args.load:\n",
    "       net.load_state_dict(\n",
    "            torch.load(args.load, map_location=device)\n",
    "            )\n",
    "       logging.info(f'Model loaded from {args.load}')\n",
    "    \n",
    "\n",
    "    net.to(device=device)\n",
    "    # faster convolutions, but more memory\n",
    "    # cudnn.benchmark = True\n",
    "\n",
    "    try:\n",
    "        train_net(net=net,\n",
    "                  epochs=args.epochs,\n",
    "                  batch_size=args.batchsize,\n",
    "                  lr=args.lr,\n",
    "                  criterion=args.criterion,\n",
    "                  device=device,\n",
    "                  img_scale=args.scale,\n",
    "                  val_percent=args.val / 100)\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(net.state_dict(), args.net+args.batchsize+'INTERRUPTED.pth')\n",
    "        logging.info('Saved interrupt')\n",
    "        try:\n",
    "            sys.exit(0)\n",
    "        except SystemExit:\n",
    "            os._exit(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsh_env",
   "language": "python",
   "name": "hsh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
